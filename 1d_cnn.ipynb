{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinemyvs/1dcnnlstm-EEG-DREAMER/blob/main/1d_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj2FTCCAdbm9",
        "outputId": "3fa7f8c3-eed6-4096-ee06-d0cb997cc939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: TensorFlow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from TensorFlow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->TensorFlow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->TensorFlow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->TensorFlow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->TensorFlow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->TensorFlow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->TensorFlow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->TensorFlow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->TensorFlow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->TensorFlow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->TensorFlow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->TensorFlow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->TensorFlow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->TensorFlow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->TensorFlow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->TensorFlow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n5YbGJxegsXc",
        "outputId": "5ddfb594-f18c-4872-9170-6a55af983d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Mounted at /content/drive\n",
            "DREAMER veri seti yükleniyor ve ön işleniyor...\n",
            "/content/drive/MyDrive/DREAMER.mat yükleniyor...\n",
            "Katılımcı 1/23 işleniyor...\n",
            "\n",
            "--- Katılımcı 1 Veri Yapısı İncelemesi (Düzeltme Sonrası) ---\n",
            "EEG L1 container tipi: <class 'numpy.ndarray'>, şekli: (1, 1)\n",
            "EEG L2 container (iç hücre dizisi) tipi: <class 'numpy.ndarray'>, şekli: (18, 1)\n",
            "EEG L2'nin ilk hücresinin (gerçek sinyal hücresi) tipi: <class 'numpy.ndarray'>\n",
            "EEG gerçek sinyal (ilk deneme) tipi: <class 'numpy.ndarray'>, şekli: (25472, 14)\n",
            "--- Bitti: Veri Yapısı İncelemesi (Düzeltme Sonrası) ---\n",
            "\n",
            "Katılımcı 2/23 işleniyor...\n",
            "Katılımcı 3/23 işleniyor...\n",
            "Katılımcı 4/23 işleniyor...\n",
            "Katılımcı 5/23 işleniyor...\n",
            "Katılımcı 6/23 işleniyor...\n",
            "Katılımcı 7/23 işleniyor...\n",
            "Katılımcı 8/23 işleniyor...\n",
            "Katılımcı 9/23 işleniyor...\n",
            "Katılımcı 10/23 işleniyor...\n",
            "Katılımcı 11/23 işleniyor...\n",
            "Katılımcı 12/23 işleniyor...\n",
            "Katılımcı 13/23 işleniyor...\n",
            "Katılımcı 14/23 işleniyor...\n",
            "Katılımcı 15/23 işleniyor...\n",
            "Katılımcı 16/23 işleniyor...\n",
            "Katılımcı 17/23 işleniyor...\n",
            "Katılımcı 18/23 işleniyor...\n",
            "Katılımcı 19/23 işleniyor...\n",
            "Katılımcı 20/23 işleniyor...\n",
            "Katılımcı 21/23 işleniyor...\n",
            "Katılımcı 22/23 işleniyor...\n",
            "Katılımcı 23/23 işleniyor...\n",
            "\n",
            "Veri yükleme ve ön işleme tamamlandı.\n",
            "Toplam 414 deneme başarıyla işlendi.\n",
            "Toplam 0 deneme sinyal kısalığı nedeniyle atlandı.\n",
            "Toplam 0 deneme veri erişim/yapı hatası nedeniyle atlandı.\n",
            "Bulunan maksimum dizi uzunluğu (padding için): 50432\n",
            "Özellik sayısı: 16, Padding için maksimum dizi uzunluğu: 50432\n",
            "\n",
            "--- Deney 1 Başlıyor: Her katılımcı için ayrı eğitim ve test ---\n",
            "Katılımcı 1: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_LSTM_Emotion_Classifier\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_LSTM_Emotion_Classifier\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1_1 (\u001b[38;5;33mConv1D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50428\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m5,184\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16809\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1_1 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16809\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1_2 (\u001b[38;5;33mConv1D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16805\u001b[0m, \u001b[38;5;34m48\u001b[0m)      │        \u001b[38;5;34m15,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5601\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1_2 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5601\u001b[0m, \u001b[38;5;34m48\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1_3 (\u001b[38;5;33mConv1D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5599\u001b[0m, \u001b[38;5;34m24\u001b[0m)       │         \u001b[38;5;34m3,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1866\u001b[0m, \u001b[38;5;34m24\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1_3 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1866\u001b[0m, \u001b[38;5;34m24\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1866\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m78,336\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_dense (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50428</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,184</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16809</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16809</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16805</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5601</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5599</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ pool1_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1866</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout1_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1866</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1866</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">78,336</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m151,881\u001b[0m (593.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">151,881</span> (593.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m151,881\u001b[0m (593.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">151,881</span> (593.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Katılımcı 2: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x78578506a480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x785787a1ec00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Katılımcı 3: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 4: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 5: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 6: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 7: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 8: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 9: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 10: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 11: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 12: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 13: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 14: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 15: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 16: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 17: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 18: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 19: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 20: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 21: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 22: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "Katılımcı 23: V(Eğt 14, Tst 4), A(Eğt 14, Tst 4)\n",
            "\n",
            "\n",
            "--- Deney 1 Özet Sonuçları ---\n",
            "Toplam 23 katılımcı için model eğitildi.\n",
            "Ortalama Valence Doğruluğu: 60.87% (Std: 14.42%)\n",
            "Ortalama Arousal Doğruluğu: 65.22% (Std: 17.66%)\n"
          ]
        }
      ],
      "source": [
        "# ----- Gerekli Kütüphanelerin Yüklenmesi (Colab'da genellikle gereksiz ama emin olmak için) -----\n",
        "!pip install numpy scipy scikit-learn tensorflow\n",
        "\n",
        "# Gerekli kütüphanelerin içe aktarılması\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from scipy.signal import butter, filtfilt, resample\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, LSTM, Dense, Input\n",
        "from tensorflow.keras.optimizers import RMSprop # Tensorflow'un yeni sürümlerinde tf.keras.optimizers.legacy.RMSprop olabilir\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import random\n",
        "\n",
        "# ----- Google Colab için Drive Bağlantısı -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) # Yeniden bağlanmayı zorla\n",
        "\n",
        "# ----- Yapılandırma Değişkenleri -----\n",
        "DREAMER_MAT_PATH_DRIVE = '/content/drive/MyDrive/DREAMER.mat'\n",
        "\n",
        "EEG_FS = 128\n",
        "ECG_FS_ORIGINAL = 256\n",
        "TARGET_FS = 128\n",
        "LOWCUT = 4.0\n",
        "HIGHCUT = 45.0\n",
        "FILTER_ORDER = 5\n",
        "MIN_SIGNAL_LENGTH_FOR_FILTER = 40\n",
        "\n",
        "LABEL_THRESHOLD = 3\n",
        "N_PARTICIPANTS = 23\n",
        "N_TRIALS_PER_PARTICIPANT_EXPECTED = 18\n",
        "TRAIN_TRIALS_MIN_REQUIRED = 5\n",
        "TEST_TRIALS_MIN_REQUIRED = 2\n",
        "\n",
        "LR = 0.0001\n",
        "EPOCHS = 2 # Hızlı test için 2 yapabilirsiniz\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "SEED = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# ----- Yardımcı Fonksiyonlar -----\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5, min_len_for_filter=MIN_SIGNAL_LENGTH_FOR_FILTER):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    if high >= 1.0: high = 0.999\n",
        "    if low <= 0.0: low = 0.001\n",
        "    if low >= high: return data\n",
        "    if not isinstance(data, np.ndarray) or data.ndim < 1 or data.shape[0] <= min_len_for_filter : return data # Eklendi: data geçerli mi kontrolü\n",
        "    try:\n",
        "        b, a = butter(order, [low, high], btype='band')\n",
        "        y = filtfilt(b, a, data, axis=0)\n",
        "    except ValueError: return data\n",
        "    return y\n",
        "\n",
        "def load_and_preprocess_dreamer(mat_file_path):\n",
        "    print(f\"{mat_file_path} yükleniyor...\")\n",
        "    try:\n",
        "        mat = scipy.io.loadmat(mat_file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"HATA: {mat_file_path} bulunamadı!\")\n",
        "        return None, None, None, 0\n",
        "    except Exception as e:\n",
        "        print(f\"HATA: {mat_file_path} yüklenirken bir hata oluştu: {e}\")\n",
        "        return None, None, None, 0\n",
        "\n",
        "    dreamer_data_struct = mat['DREAMER'][0, 0]\n",
        "    all_participants_data_list = []\n",
        "    all_participants_valence_labels_list = []\n",
        "    all_participants_arousal_labels_list = []\n",
        "    max_len_overall = 0\n",
        "    total_trials_processed_successfully = 0\n",
        "    total_trials_skipped_short_signal = 0\n",
        "    total_trials_skipped_access_error = 0\n",
        "\n",
        "    for p_idx in range(N_PARTICIPANTS):\n",
        "        print(f\"Katılımcı {p_idx + 1}/{N_PARTICIPANTS} işleniyor...\")\n",
        "\n",
        "        if p_idx == 0: # Sadece ilk katılımcı için detaylı inceleme\n",
        "            print(f\"\\n--- Katılımcı {p_idx+1} Veri Yapısı İncelemesi (Düzeltme Sonrası) ---\")\n",
        "            try:\n",
        "                participant_struct_debug = dreamer_data_struct['Data'][0, p_idx]\n",
        "                # 1. Katman\n",
        "                eeg_stim_container_L1_debug = participant_struct_debug['EEG'][0,0]['stimuli']\n",
        "                print(f\"EEG L1 container tipi: {type(eeg_stim_container_L1_debug)}, şekli: {eeg_stim_container_L1_debug.shape if isinstance(eeg_stim_container_L1_debug, np.ndarray) else 'N/A'}\")\n",
        "\n",
        "                if isinstance(eeg_stim_container_L1_debug, np.ndarray) and eeg_stim_container_L1_debug.shape == (1,1):\n",
        "                    # 2. Katman\n",
        "                    eeg_stim_container_L2_debug = eeg_stim_container_L1_debug[0,0]\n",
        "                    print(f\"EEG L2 container (iç hücre dizisi) tipi: {type(eeg_stim_container_L2_debug)}, şekli: {eeg_stim_container_L2_debug.shape if isinstance(eeg_stim_container_L2_debug, np.ndarray) else 'N/A'}\")\n",
        "\n",
        "                    if isinstance(eeg_stim_container_L2_debug, np.ndarray) and eeg_stim_container_L2_debug.shape == (N_TRIALS_PER_PARTICIPANT_EXPECTED, 1):\n",
        "                        # 3. Katman (asıl sinyal verisi)\n",
        "                        eeg_actual_signal_cell_debug = eeg_stim_container_L2_debug[0,0] # İlk denemenin hücresi\n",
        "                        print(f\"EEG L2'nin ilk hücresinin (gerçek sinyal hücresi) tipi: {type(eeg_actual_signal_cell_debug)}\")\n",
        "                        if isinstance(eeg_actual_signal_cell_debug, np.ndarray):\n",
        "                             print(f\"EEG gerçek sinyal (ilk deneme) tipi: {type(eeg_actual_signal_cell_debug)}, şekli: {eeg_actual_signal_cell_debug.shape}\")\n",
        "                        else: # Belki .item() gerekir\n",
        "                            try:\n",
        "                                eeg_actual_signal_via_item = eeg_actual_signal_cell_debug.item()\n",
        "                                print(f\"EEG gerçek sinyal (ilk deneme, .item() ile) tipi: {type(eeg_actual_signal_via_item)}, şekli: {eeg_actual_signal_via_item.shape if isinstance(eeg_actual_signal_via_item, np.ndarray) else 'N/A'}\")\n",
        "                            except Exception as e_item_inner:\n",
        "                                print(f\"Gerçek sinyal hücresine .item() hatası: {e_item_inner}\")\n",
        "                print(\"--- Bitti: Veri Yapısı İncelemesi (Düzeltme Sonrası) ---\\n\")\n",
        "            except Exception as e_debug_print:\n",
        "                print(f\"Debug yazdırma sırasında hata: {e_debug_print}\")\n",
        "\n",
        "        try:\n",
        "            participant_struct = dreamer_data_struct['Data'][0, p_idx]\n",
        "            valence_scores_for_participant = participant_struct['ScoreValence'][0,0].flatten()\n",
        "            arousal_scores_for_participant = participant_struct['ScoreArousal'][0,0].flatten()\n",
        "\n",
        "            # Düzeltilmiş Erişim:\n",
        "            eeg_inner_cell_array = participant_struct['EEG'][0,0]['stimuli'][0,0]\n",
        "            ecg_inner_cell_array = participant_struct['ECG'][0,0]['stimuli'][0,0]\n",
        "\n",
        "        except (IndexError, KeyError, TypeError) as e_access_main: # TypeError eklendi (NoneType üzerinde işlem yapmaya çalışırsa)\n",
        "            print(f\"HATA: Katılımcı {p_idx+1} için ana veri alanlarına erişirken hata ({e_access_main}). Bu katılımcı atlanıyor.\")\n",
        "            all_participants_data_list.append([])\n",
        "            all_participants_valence_labels_list.append(np.array([]))\n",
        "            all_participants_arousal_labels_list.append(np.array([]))\n",
        "            total_trials_skipped_access_error += N_TRIALS_PER_PARTICIPANT_EXPECTED\n",
        "            continue\n",
        "\n",
        "        participant_trials_data_list = []\n",
        "        participant_trials_valence_labels = []\n",
        "        participant_trials_arousal_labels = []\n",
        "\n",
        "        if not (isinstance(eeg_inner_cell_array, np.ndarray) and \\\n",
        "                eeg_inner_cell_array.ndim == 2 and eeg_inner_cell_array.shape[1] == 1 and \\\n",
        "                eeg_inner_cell_array.shape[0] >= 1 and \\\n",
        "                isinstance(ecg_inner_cell_array, np.ndarray) and \\\n",
        "                ecg_inner_cell_array.ndim == 2 and ecg_inner_cell_array.shape[1] == 1 and \\\n",
        "                ecg_inner_cell_array.shape[0] == eeg_inner_cell_array.shape[0]):\n",
        "            print(f\"Katılımcı {p_idx+1} için iç stimuli hücre dizisi beklenmedik şekle/tipe sahip veya EEG/EKG uyuşmuyor. EEG: {eeg_inner_cell_array.shape if isinstance(eeg_inner_cell_array, np.ndarray) else type(eeg_inner_cell_array)}, ECG: {ecg_inner_cell_array.shape if isinstance(ecg_inner_cell_array, np.ndarray) else type(ecg_inner_cell_array)}. Atlanıyor.\")\n",
        "            all_participants_data_list.append([])\n",
        "            all_participants_valence_labels_list.append(np.array([]))\n",
        "            all_participants_arousal_labels_list.append(np.array([]))\n",
        "            total_trials_skipped_access_error += eeg_inner_cell_array.shape[0] if isinstance(eeg_inner_cell_array, np.ndarray) else N_TRIALS_PER_PARTICIPANT_EXPECTED\n",
        "            continue\n",
        "\n",
        "        n_actual_trials = eeg_inner_cell_array.shape[0]\n",
        "\n",
        "        for t_idx in range(n_actual_trials):\n",
        "            eeg_stimuli_raw = None\n",
        "            ecg_stimuli_raw = None\n",
        "            try:\n",
        "                eeg_cell_content = eeg_inner_cell_array[t_idx, 0]\n",
        "                ecg_cell_content = ecg_inner_cell_array[t_idx, 0]\n",
        "\n",
        "                # Hücre içeriği genellikle doğrudan numpy array'dir bu seviyede.\n",
        "                if isinstance(eeg_cell_content, np.ndarray) and eeg_cell_content.ndim >= 2:\n",
        "                    eeg_stimuli_raw = eeg_cell_content\n",
        "                else: # .item() çok nadir gerekir, genellikle hata verir\n",
        "                    # print(f\"Katılımcı {p_idx+1}, Deneme {t_idx+1} EEG hücre içeriği beklenmedik tip: {type(eeg_cell_content)}\")\n",
        "                    total_trials_skipped_access_error += 1\n",
        "                    continue # Bu denemeyi atla\n",
        "\n",
        "                if isinstance(ecg_cell_content, np.ndarray) and ecg_cell_content.ndim >= 2:\n",
        "                    ecg_stimuli_raw = ecg_cell_content\n",
        "                else:\n",
        "                    # print(f\"Katılımcı {p_idx+1}, Deneme {t_idx+1} ECG hücre içeriği beklenmedik tip: {type(ecg_cell_content)}\")\n",
        "                    total_trials_skipped_access_error += 1\n",
        "                    continue # Bu denemeyi atla\n",
        "\n",
        "            except Exception as e_cell_access:\n",
        "                # print(f\"Katılımcı {p_idx+1}, Deneme {t_idx+1} hücre içeriği alınırken hata ({e_cell_access}). Atlanıyor.\")\n",
        "                total_trials_skipped_access_error += 1\n",
        "                continue\n",
        "\n",
        "            if eeg_stimuli_raw is None or ecg_stimuli_raw is None or \\\n",
        "               eeg_stimuli_raw.shape[0] == 0 or ecg_stimuli_raw.shape[0] == 0:\n",
        "                # print(f\"Katılımcı {p_idx+1}, Deneme {t_idx+1} ham sinyal boş veya alınamadı. Atlanıyor.\")\n",
        "                total_trials_skipped_access_error += 1\n",
        "                continue\n",
        "\n",
        "            if eeg_stimuli_raw.shape[0] < MIN_SIGNAL_LENGTH_FOR_FILTER or \\\n",
        "               ecg_stimuli_raw.shape[0] < (MIN_SIGNAL_LENGTH_FOR_FILTER * ECG_FS_ORIGINAL / TARGET_FS):\n",
        "                total_trials_skipped_short_signal += 1\n",
        "                continue\n",
        "\n",
        "            eeg_stimuli_filtered = butter_bandpass_filter(eeg_stimuli_raw, LOWCUT, HIGHCUT, EEG_FS)\n",
        "\n",
        "            num_samples_original_ecg = ecg_stimuli_raw.shape[0]\n",
        "            num_samples_target_ecg = int(num_samples_original_ecg * TARGET_FS / ECG_FS_ORIGINAL)\n",
        "            if num_samples_target_ecg < MIN_SIGNAL_LENGTH_FOR_FILTER:\n",
        "                total_trials_skipped_short_signal += 1\n",
        "                continue\n",
        "\n",
        "            # EKG kanallarının (genellikle 2) doğru olduğundan emin ol\n",
        "            if ecg_stimuli_raw.shape[1] == 0:\n",
        "                # print(f\"Katılımcı {p_idx+1}, Deneme {t_idx+1} EKG sinyalinde kanal yok. Atlanıyor.\")\n",
        "                total_trials_skipped_access_error += 1\n",
        "                continue\n",
        "\n",
        "            ecg_downsampled = np.zeros((num_samples_target_ecg, ecg_stimuli_raw.shape[1]))\n",
        "            for ch_idx in range(ecg_stimuli_raw.shape[1]):\n",
        "                 ecg_downsampled[:, ch_idx] = resample(ecg_stimuli_raw[:, ch_idx], num_samples_target_ecg)\n",
        "            ecg_stimuli_filtered = butter_bandpass_filter(ecg_downsampled, LOWCUT, HIGHCUT, TARGET_FS)\n",
        "\n",
        "            if (eeg_stimuli_filtered is eeg_stimuli_raw and eeg_stimuli_raw.shape[0] < MIN_SIGNAL_LENGTH_FOR_FILTER) or \\\n",
        "               (ecg_stimuli_filtered is ecg_downsampled and ecg_downsampled.shape[0] < MIN_SIGNAL_LENGTH_FOR_FILTER):\n",
        "                total_trials_skipped_short_signal += 1\n",
        "                continue\n",
        "\n",
        "            min_trial_segment_len = min(eeg_stimuli_filtered.shape[0], ecg_stimuli_filtered.shape[0])\n",
        "            if min_trial_segment_len == 0:\n",
        "                total_trials_skipped_short_signal +=1\n",
        "                continue\n",
        "\n",
        "            eeg_stimuli_aligned = eeg_stimuli_filtered[:min_trial_segment_len, :]\n",
        "            ecg_stimuli_aligned = ecg_stimuli_filtered[:min_trial_segment_len, :]\n",
        "\n",
        "            if min_trial_segment_len > max_len_overall: max_len_overall = min_trial_segment_len\n",
        "\n",
        "            combined_features_for_trial = np.hstack((eeg_stimuli_aligned, ecg_stimuli_aligned))\n",
        "            participant_trials_data_list.append(combined_features_for_trial)\n",
        "\n",
        "            if t_idx < len(valence_scores_for_participant) and t_idx < len(arousal_scores_for_participant):\n",
        "                participant_trials_valence_labels.append(1 if valence_scores_for_participant[t_idx] >= LABEL_THRESHOLD else 0)\n",
        "                participant_trials_arousal_labels.append(1 if arousal_scores_for_participant[t_idx] >= LABEL_THRESHOLD else 0)\n",
        "                total_trials_processed_successfully +=1\n",
        "            else:\n",
        "                # print(f\"Katılımcı {p_idx+1}, Deneme {t_idx+1} için skor bulunamadı (indeks dışı). Atlanıyor.\")\n",
        "                if participant_trials_data_list: participant_trials_data_list.pop() # Eklenen veriyi geri al\n",
        "                total_trials_skipped_access_error +=1\n",
        "\n",
        "        if not participant_trials_data_list:\n",
        "            all_participants_data_list.append([])\n",
        "            all_participants_valence_labels_list.append(np.array([]))\n",
        "            all_participants_arousal_labels_list.append(np.array([]))\n",
        "        else:\n",
        "            all_participants_data_list.append(participant_trials_data_list)\n",
        "            all_participants_valence_labels_list.append(np.array(participant_trials_valence_labels))\n",
        "            all_participants_arousal_labels_list.append(np.array(participant_trials_arousal_labels))\n",
        "\n",
        "    print(f\"\\nVeri yükleme ve ön işleme tamamlandı.\")\n",
        "    print(f\"Toplam {total_trials_processed_successfully} deneme başarıyla işlendi.\")\n",
        "    print(f\"Toplam {total_trials_skipped_short_signal} deneme sinyal kısalığı nedeniyle atlandı.\")\n",
        "    print(f\"Toplam {total_trials_skipped_access_error} deneme veri erişim/yapı hatası nedeniyle atlandı.\")\n",
        "    print(f\"Bulunan maksimum dizi uzunluğu (padding için): {max_len_overall}\")\n",
        "\n",
        "    if max_len_overall == 0 and total_trials_processed_successfully == 0 :\n",
        "        print(\"KRİTİK HATA: Hiçbir katılımcıdan geçerli veri işlenemedi. max_len_overall sıfır.\")\n",
        "        return None, None, None, 0\n",
        "    return all_participants_data_list, all_participants_valence_labels_list, all_participants_arousal_labels_list, max_len_overall\n",
        "\n",
        "# ----- create_cnn_lstm_model ve Ana Kod Akışı (öncekiyle aynı) -----\n",
        "def create_cnn_lstm_model(input_shape_tuple):\n",
        "    model = Sequential(name=\"CNN_LSTM_Emotion_Classifier\")\n",
        "    model.add(Input(shape=input_shape_tuple))\n",
        "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu', name='conv1_1'))\n",
        "    model.add(MaxPooling1D(pool_size=3, name='pool1_1'))\n",
        "    model.add(Dropout(0.2, name='dropout1_1'))\n",
        "    model.add(Conv1D(filters=48, kernel_size=5, activation='relu', name='conv1_2'))\n",
        "    model.add(MaxPooling1D(pool_size=3, name='pool1_2'))\n",
        "    model.add(Dropout(0.2, name='dropout1_2'))\n",
        "    model.add(Conv1D(filters=24, kernel_size=3, activation='relu', name='conv1_3'))\n",
        "    model.add(MaxPooling1D(pool_size=3, name='pool1_3'))\n",
        "    model.add(Dropout(0.2, name='dropout1_3'))\n",
        "    model.add(LSTM(128, return_sequences=True, name='lstm_1'))\n",
        "    model.add(LSTM(64, name='lstm_2'))\n",
        "    model.add(Dense(1, activation='sigmoid', name='output_dense'))\n",
        "    try:\n",
        "        optimizer = RMSprop(learning_rate=LR)\n",
        "    except TypeError: # Eski TF sürümleri için\n",
        "        optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=LR)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ----- Ana Kod Akışı -----\n",
        "if not os.path.exists(DREAMER_MAT_PATH_DRIVE):\n",
        "    print(f\"HATA: DREAMER.mat dosyası {DREAMER_MAT_PATH_DRIVE} konumunda bulunamadı.\")\n",
        "else:\n",
        "    print(\"DREAMER veri seti yükleniyor ve ön işleniyor...\")\n",
        "    all_participants_processed_data, all_participants_valence_labels, \\\n",
        "    all_participants_arousal_labels, max_sequence_len = load_and_preprocess_dreamer(DREAMER_MAT_PATH_DRIVE)\n",
        "\n",
        "    if all_participants_processed_data is None or max_sequence_len == 0:\n",
        "        print(\"Veri yükleme başarısız oldu veya işlenecek veri bulunamadı. Program sonlandırılıyor.\")\n",
        "    else:\n",
        "        num_total_features = 0\n",
        "        first_valid_participant_for_features = -1\n",
        "        # Özellik sayısını ve ilk geçerli katılımcıyı bul\n",
        "        for i, p_data_list in enumerate(all_participants_processed_data):\n",
        "            if p_data_list: # Katılımcının deneme listesi boş değilse\n",
        "                # Bu listedeki ilk geçerli (boş olmayan) denemeyi bul\n",
        "                for trial_data in p_data_list:\n",
        "                    if isinstance(trial_data, np.ndarray) and trial_data.shape[0] > 0 and trial_data.ndim == 2:\n",
        "                        num_total_features = trial_data.shape[1]\n",
        "                        first_valid_participant_for_features = i\n",
        "                        break # İç döngüden çık\n",
        "                if num_total_features > 0:\n",
        "                    break # Dış döngüden çık\n",
        "\n",
        "        if num_total_features == 0:\n",
        "             print(\"UYARI: Özellik sayısı belirlenemedi (num_total_features = 0). Model eğitimi atlanıyor.\")\n",
        "        else:\n",
        "            print(f\"Özellik sayısı: {num_total_features}, Padding için maksimum dizi uzunluğu: {max_sequence_len}\")\n",
        "            participant_specific_valence_accuracies = []\n",
        "            participant_specific_arousal_accuracies = []\n",
        "            valid_participants_count_for_training = 0 # Model eğitimi yapılan katılımcı sayısı\n",
        "            print(\"\\n--- Deney 1 Başlıyor: Her katılımcı için ayrı eğitim ve test ---\")\n",
        "\n",
        "            for p_idx in range(N_PARTICIPANTS):\n",
        "                current_participant_data_trials = all_participants_processed_data[p_idx]\n",
        "                current_participant_valence_labels = all_participants_valence_labels[p_idx] # Bu bir numpy array olmalı\n",
        "                current_participant_arousal_labels = all_participants_arousal_labels[p_idx] # Bu da\n",
        "\n",
        "                # Etiketlerin de numpy array olduğundan ve boş olmadığından emin ol\n",
        "                if not isinstance(current_participant_valence_labels, np.ndarray) or \\\n",
        "                   not isinstance(current_participant_arousal_labels, np.ndarray) or \\\n",
        "                   current_participant_valence_labels.size == 0 or \\\n",
        "                   current_participant_arousal_labels.size == 0:\n",
        "                    # print(f\"Katılımcı {p_idx + 1} için etiketler eksik veya geçersiz. Atlanıyor.\")\n",
        "                    continue\n",
        "\n",
        "                # Veri ve etiket sayısının eşleştiğinden emin ol\n",
        "                if not current_participant_data_trials or \\\n",
        "                   len(current_participant_data_trials) != len(current_participant_valence_labels) or \\\n",
        "                   len(current_participant_data_trials) < (TRAIN_TRIALS_MIN_REQUIRED + TEST_TRIALS_MIN_REQUIRED):\n",
        "                    # print(f\"Katılımcı {p_idx + 1} için yeterli/uyumlu veri/etiket yok ({len(current_participant_data_trials)} veri, {len(current_participant_valence_labels)} etiket). Atlanıyor.\")\n",
        "                    continue\n",
        "\n",
        "                trial_indices_for_participant = np.arange(len(current_participant_data_trials))\n",
        "                n_trials_for_participant = len(current_participant_data_trials)\n",
        "\n",
        "                current_test_size = TEST_TRIALS_MIN_REQUIRED\n",
        "                # Test boyutunu, mevcut deneme sayısına ve beklenen orana göre ayarla\n",
        "                potential_test_size = int(round(n_trials_for_participant * (4.0/N_TRIALS_PER_PARTICIPANT_EXPECTED)))\n",
        "                if potential_test_size >= TEST_TRIALS_MIN_REQUIRED:\n",
        "                    current_test_size = potential_test_size\n",
        "\n",
        "                # Eğitim için yeterli deneme kalıp kalmadığını kontrol et\n",
        "                if n_trials_for_participant - current_test_size < TRAIN_TRIALS_MIN_REQUIRED:\n",
        "                    # print(f\"Katılımcı {p_idx + 1} için test boyutu ({current_test_size}) sonrası yeterli eğitim denemesi ({n_trials_for_participant - current_test_size}) kalmıyor. Atlanıyor.\")\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Etiketlerin en az iki farklı sınıfa sahip olup olmadığını kontrol et (stratify için)\n",
        "                    stratify_val = current_participant_valence_labels if len(np.unique(current_participant_valence_labels)) > 1 else None\n",
        "                    train_trial_indices_v, test_trial_indices_v = train_test_split(\n",
        "                        trial_indices_for_participant, test_size=current_test_size, random_state=SEED, shuffle=True, stratify=stratify_val)\n",
        "\n",
        "                    stratify_aro = current_participant_arousal_labels if len(np.unique(current_participant_arousal_labels)) > 1 else None\n",
        "                    train_trial_indices_a, test_trial_indices_a = train_test_split(\n",
        "                        trial_indices_for_participant, test_size=current_test_size, random_state=SEED, shuffle=True, stratify=stratify_aro)\n",
        "\n",
        "                except ValueError as e_split: # Stratify başarısız olursa\n",
        "                    # print(f\"Katılımcı {p_idx + 1} için stratify ile bölme hatası ({e_split}). Basit bölme deneniyor.\")\n",
        "                    try:\n",
        "                        train_trial_indices_v, test_trial_indices_v = train_test_split(\n",
        "                            trial_indices_for_participant, test_size=current_test_size, random_state=SEED, shuffle=True)\n",
        "                        train_trial_indices_a, test_trial_indices_a = train_test_split(\n",
        "                            trial_indices_for_participant, test_size=current_test_size, random_state=SEED, shuffle=True)\n",
        "                    except Exception as e_split_again:\n",
        "                        # print(f\"Katılımcı {p_idx + 1} için ikinci train_test_split denemesinde de hata ({e_split_again}). Atlanıyor.\")\n",
        "                        continue\n",
        "\n",
        "                # Valence için\n",
        "                X_train_v_list = [current_participant_data_trials[i] for i in train_trial_indices_v]\n",
        "                X_test_v_list = [current_participant_data_trials[i] for i in test_trial_indices_v]\n",
        "                y_train_v_labels = current_participant_valence_labels[train_trial_indices_v]\n",
        "                y_test_v_labels = current_participant_valence_labels[test_trial_indices_v]\n",
        "\n",
        "                # Arousal için\n",
        "                X_train_a_list = [current_participant_data_trials[i] for i in train_trial_indices_a]\n",
        "                X_test_a_list = [current_participant_data_trials[i] for i in test_trial_indices_a]\n",
        "                y_train_a_labels = current_participant_arousal_labels[train_trial_indices_a]\n",
        "                y_test_a_labels = current_participant_arousal_labels[test_trial_indices_a]\n",
        "\n",
        "\n",
        "                if not X_train_v_list or not X_test_v_list or not X_train_a_list or not X_test_a_list :\n",
        "                    # print(f\"Katılımcı {p_idx + 1} için eğitim veya test listeleri boş. Atlanıyor.\")\n",
        "                    continue\n",
        "\n",
        "                # Valence için ölçekleme ve padding\n",
        "                temp_train_v_concat = np.vstack(X_train_v_list)\n",
        "                if temp_train_v_concat.shape[0] == 0: continue\n",
        "                scaler_v = MinMaxScaler().fit(temp_train_v_concat)\n",
        "                X_train_v_scaled = [scaler_v.transform(trial) for trial in X_train_v_list]\n",
        "                X_test_v_scaled = [scaler_v.transform(trial) for trial in X_test_v_list]\n",
        "                X_train_v_padded = pad_sequences(X_train_v_scaled, maxlen=max_sequence_len, dtype='float32', padding='post', truncating='post')\n",
        "                X_test_v_padded = pad_sequences(X_test_v_scaled, maxlen=max_sequence_len, dtype='float32', padding='post', truncating='post')\n",
        "\n",
        "                # Arousal için ölçekleme ve padding\n",
        "                temp_train_a_concat = np.vstack(X_train_a_list)\n",
        "                if temp_train_a_concat.shape[0] == 0: continue\n",
        "                scaler_a = MinMaxScaler().fit(temp_train_a_concat)\n",
        "                X_train_a_scaled = [scaler_a.transform(trial) for trial in X_train_a_list]\n",
        "                X_test_a_scaled = [scaler_a.transform(trial) for trial in X_test_a_list]\n",
        "                X_train_a_padded = pad_sequences(X_train_a_scaled, maxlen=max_sequence_len, dtype='float32', padding='post', truncating='post')\n",
        "                X_test_a_padded = pad_sequences(X_test_a_scaled, maxlen=max_sequence_len, dtype='float32', padding='post', truncating='post')\n",
        "\n",
        "\n",
        "                if X_train_v_padded.shape[0] == 0 or X_test_v_padded.shape[0] == 0 or \\\n",
        "                   X_train_a_padded.shape[0] == 0 or X_test_a_padded.shape[0] == 0:\n",
        "                    # print(f\"Katılımcı {p_idx + 1} için padding sonrası veri boş. Atlanıyor.\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"Katılımcı {p_idx + 1}: V(Eğt {X_train_v_padded.shape[0]}, Tst {X_test_v_padded.shape[0]}), A(Eğt {X_train_a_padded.shape[0]}, Tst {X_test_a_padded.shape[0]})\")\n",
        "                valid_participants_count_for_training += 1\n",
        "                model_input_shape = (max_sequence_len, num_total_features)\n",
        "\n",
        "                # Valence Modeli\n",
        "                model_valence = create_cnn_lstm_model(model_input_shape)\n",
        "                if p_idx == first_valid_participant_for_features : model_valence.summary()\n",
        "                history_valence = model_valence.fit(X_train_v_padded, y_train_v_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0, validation_data=(X_test_v_padded, y_test_v_labels))\n",
        "                loss_v, acc_v = model_valence.evaluate(X_test_v_padded, y_test_v_labels, verbose=0)\n",
        "                participant_specific_valence_accuracies.append(acc_v)\n",
        "\n",
        "                # Arousal Modeli\n",
        "                model_arousal = create_cnn_lstm_model(model_input_shape)\n",
        "                history_arousal = model_arousal.fit(X_train_a_padded, y_train_a_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0, validation_data=(X_test_a_padded, y_test_a_labels))\n",
        "                loss_a, acc_a = model_arousal.evaluate(X_test_a_padded, y_test_a_labels, verbose=0)\n",
        "                participant_specific_arousal_accuracies.append(acc_a)\n",
        "\n",
        "                tf.keras.backend.clear_session() # Belleği temizle\n",
        "\n",
        "            if not participant_specific_valence_accuracies: # Eğer hiç geçerli katılımcı işlenemediyse\n",
        "                avg_valence_accuracy_exp1, std_valence_accuracy_exp1 = 0.0, 0.0\n",
        "                avg_arousal_accuracy_exp1, std_arousal_accuracy_exp1 = 0.0, 0.0\n",
        "            else:\n",
        "                avg_valence_accuracy_exp1 = np.mean(participant_specific_valence_accuracies)\n",
        "                std_valence_accuracy_exp1 = np.std(participant_specific_valence_accuracies)\n",
        "                avg_arousal_accuracy_exp1 = np.mean(participant_specific_arousal_accuracies)\n",
        "                std_arousal_accuracy_exp1 = np.std(participant_specific_arousal_accuracies)\n",
        "\n",
        "            print(\"\\n\\n--- Deney 1 Özet Sonuçları ---\")\n",
        "            print(f\"Toplam {valid_participants_count_for_training} katılımcı için model eğitildi.\")\n",
        "            print(f\"Ortalama Valence Doğruluğu: {avg_valence_accuracy_exp1*100:.2f}% (Std: {std_valence_accuracy_exp1*100:.2f}%)\")\n",
        "            print(f\"Ortalama Arousal Doğruluğu: {avg_arousal_accuracy_exp1*100:.2f}% (Std: {std_arousal_accuracy_exp1*100:.2f}%)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPndEvofF1wxPAwsLury6Oh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}